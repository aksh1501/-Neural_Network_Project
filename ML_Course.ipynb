{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+0QZixOWgYZMApeGvSyKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksh1501/-Neural_Network_Project/blob/main/ML_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u6a5eLi52Wz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The kernel trick is a technique used in machine learning, particularly in Support Vector Machines (SVMs), to implicitly map input data into higher-dimensional feature spaces without explicitly computing the transformation. This technique allows SVMs to efficiently handle non-linear decision boundaries by transforming the data into a space where a linear decision boundary can be applied.\n",
        "\n",
        "In traditional SVMs, the decision boundary is a hyperplane that separates data points into different classes. However, in many real-world scenarios, the data may not be linearly separable in the original feature space. The kernel trick provides a way to deal with such situations by mapping the input data into a higher-dimensional space where it may become linearly separable.\n",
        "\n",
        "Mathematically, the kernel trick involves replacing the dot product of feature vectors in the input space with a kernel function. The kernel function calculates the similarity between pairs of data points in the input space. The most commonly used kernel functions include:\n",
        "\n",
        "1. **Linear Kernel**: \\( K(x_i, x_j) = x_i^T x_j \\)\n",
        "2. **Polynomial Kernel**: \\( K(x_i, x_j) = (x_i^T x_j + c)^d \\)\n",
        "3. **Gaussian (RBF) Kernel**: \\( K(x_i, x_j) = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{2\\sigma^2}\\right) \\)\n",
        "4. **Sigmoid Kernel**: \\( K(x_i, x_j) = \\tanh(\\alpha x_i^T x_j + c) \\)\n",
        "\n",
        "These kernel functions allow SVMs to implicitly compute the dot products in higher-dimensional spaces without explicitly transforming the input data. This is computationally more efficient, especially when dealing with high-dimensional data or when the explicit transformation into a higher-dimensional space is infeasible due to computational constraints.\n",
        "\n",
        "By using the kernel trick, SVMs can learn complex decision boundaries that may not be possible to represent in the original feature space. This makes SVMs with kernel functions powerful tools for handling non-linear classification tasks and has made them widely used in various machine learning applications."
      ],
      "metadata": {
        "id": "jHaZci2-56pU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "etFYBbkFygou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix is a table that is often used to evaluate the performance of a classification model. It compares the actual labels of a dataset with the labels predicted by the model. The matrix consists of four different combinations of predicted and actual classes:\n",
        "\n",
        "1. True Positives (TP): The cases in which the model correctly predicted the positive class.\n",
        "2. True Negatives (TN): The cases in which the model correctly predicted the negative class.\n",
        "3. False Positives (FP): The cases in which the model incorrectly predicted the positive class when the actual class was negative. (Also known as Type I error)\n",
        "4. False Negatives (FN): The cases in which the model incorrectly predicted the negative class when the actual class was positive. (Also known as Type II error)\n",
        "\n",
        "The confusion matrix is typically laid out as follows:\n",
        "\n",
        "```\n",
        "              Predicted Negative   Predicted Positive\n",
        "Actual Negative        TN                   FP\n",
        "Actual Positive        FN                   TP\n",
        "```\n",
        "\n",
        "Here's a brief explanation of each cell in the confusion matrix:\n",
        "\n",
        "- True Negatives (TN): The model correctly predicted negative instances as negative.\n",
        "- False Positives (FP): The model incorrectly predicted negative instances as positive.\n",
        "- False Negatives (FN): The model incorrectly predicted positive instances as negative.\n",
        "- True Positives (TP): The model correctly predicted positive instances as positive.\n",
        "\n",
        "The confusion matrix provides valuable insights into the performance of a classification model, such as accuracy, precision, recall (sensitivity), specificity, and F1 score. These metrics can help assess the model's performance across different classes and identify areas for improvement."
      ],
      "metadata": {
        "id": "D0Tg4G6Oygy4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mDl_sOBCTrir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi Ritu and Rinkesh,\n",
        "\n",
        "The lecture-15 will be a self-study session towards a 15-marks section\n",
        "in the final exam. Please share the following guidelines with your\n",
        "colleagues for the same:\n",
        "\n",
        "1. Allotted marks: 15(out of 75)\n",
        "2. Expected response-template for the task:\n",
        "    1. Summarize the research paper assigned to you in STARR format:\n",
        "       1. Situation:\n",
        "          1. Problem statement\n",
        "          2. Sample test-cases + edge-cases\n",
        "          3. Why the problem is important?\n",
        "          4. Gap areas identified in the paper\n",
        "          5. Proposed merits of the work\n",
        "        2. Task:\n",
        "           1. Methodology in brief\n",
        "              1. Evaluation metric\n",
        "              2. Algorithm\n",
        "        3. Action and Results:\n",
        "           1. Experiment design: Ignore hardware/software details, focus\n",
        "on experiment-design only: For instance, which X vs Y tables were\n",
        "reported and why?\n",
        "           2. A brief 1-2 sentence summary of experiment results.\n",
        "        4. Retrospectives: (Can add your commentary, since the papers may\n",
        "be outdated in the light of current state of tech.)\n",
        "           1. Merits of the proposed solution?\n",
        "           2. Limitations of the proposed solution?\n",
        "3. Logistics:\n",
        "    1. How the assessment process looks like for this portion?\n",
        "       1. Papers will be assigned at the end of lecture-14. 2 students\n",
        "per group.\n",
        "       2. Modality of the attempt: As a 15 marks section in the final\n",
        "theory exam.\n",
        "       3. Deadline for the task: The final exam.\n",
        "       4. Method of evaluation:\n",
        "          1. STARR adherence\n",
        "          2. Clarity\n",
        "          3. Correctness of the response: A higher precision is expected.\n",
        "\n",
        "\n",
        "Feel free to reach-out if the guideline is not clear.\n",
        "\n",
        "Regards,\n",
        "Pranav"
      ],
      "metadata": {
        "id": "KdZBiDagTruo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q0_169B0Trxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-oWQccAYTr0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MML6voHBTr3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iPfl0eWWTr6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eUTUh5jATr9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4A7LgfJGTr_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VQswnQKTTsC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ecraj-SLTsFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_nKOw8bwTsIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZKARc-DwTsLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mh9rCFGPTsN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nuGprwgxTsQw"
      }
    }
  ]
}